{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Load and Execute Paddle Model\n\nIn this tutorial, we will show you how to load and execute a paddle model in CINN.\nWe offer you four optional models: ResNet50, MobileNetV2, EfficientNet and FaceDet.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import paddle\nimport paddle.fluid as fluid\nimport cinn\nfrom cinn import *\nfrom cinn.frontend import *\nfrom cinn.framework import *\nfrom cinn.common import *\nimport numpy as np\nimport os\nimport sys\n# sphinx_gallery_thumbnail_path = './paddlepaddle.png'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Prepare to Load Model**\nDeclare the params and prepare to load and execute the paddle model.\n\n- :code:`model_dir` is the path where the paddle model is stored.\n\n- :code:`input_tensor` is the name of input tensor in the model.\n\n- :code:`target_tensor` is the name of output tensor we want.\n\n- :code:`x_shape` is the input tensor's shape of the model\n\n- When choosing model ResNet50, the params should be ::\n\n      model_dir = \"./ResNet50\"\n\n      input_tensor = 'inputs'\n\n      target_tensor = 'save_infer_model/scale_0.tmp_1'\n\n      x_shape = [1, 3, 224, 224]\n\n- When choosing model MobileNetV2, the params should be ::\n\n      model_dir = \"./MobileNetV2\"\n\n      input_tensor = 'image'\n\n      target_tensor = 'save_infer_model/scale_0'\n\n      x_shape = [1, 3, 224, 224]\n\n- When choosing model EfficientNet, the params should be ::\n\n      model_dir = \"./EfficientNet\"\n\n      input_tensor = 'image'\n\n      target_tensor = 'save_infer_model/scale_0'\n\n      x_shape = [1, 3, 224, 224]\n\n- When choosing model FaceDet, the params should be ::\n\n      model_dir = \"./FaceDet\"\n\n      input_tensor = 'image'\n\n      target_tensor = 'save_infer_model/scale_0'\n\n      x_shape = [1, 3, 240, 320]\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model_dir = \"./ResNet50\"\ninput_tensor = 'inputs'\ntarget_tensor = 'save_infer_model/scale_0.tmp_1'\nx_shape = [1, 3, 224, 224]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Set the target backend**\nNow CINN only supports two backends: X86 and CUDA.\n\n- For CUDA backends, set ``target = DefaultNVGPUTarget()``\n\n- For X86 backends, set ``target = DefaultHostTarget()``\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if os.path.exists(\"is_cuda\"):\n    target = DefaultNVGPUTarget()\nelse:\n    target = DefaultHostTarget()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Load Model to CINN**\nLoad the paddle model and transform it into CINN IR.\n\n* :code:`target` is the backend to execute model on.\n\n* :code:`model_dir` is the path where the paddle model is stored.\n\n* :code:`params_combined` implies whether the params of paddle model is stored in one file.\n\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "params_combined = True\ncomputation = Computation.compile_paddle_model(\n    target, model_dir, [input_tensor], [x_shape], params_combined)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Get input tensor and set input data**\nHere we use random data as input. In practical applications,\nplease replace it with real data according to your needs.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "a_t = computation.get_tensor(input_tensor)\nx_data = np.random.random(x_shape).astype(\"float32\")\na_t.from_numpy(x_data, target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here we set the output tensor's data to zero before running the model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "out = computation.get_tensor(target_tensor)\nout.from_numpy(np.zeros(out.shape(), dtype='float32'), target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Execute Model**\nExecute the model and get output tensor's data.\n:code:`out` is the data of output tensor we want.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "computation.execute()\nres_cinn = out.numpy(target)\nprint(\"CINN Execution Done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Use Paddle to Verify Correctness**\nNow we run the model by paddle and check if the 2 results are identical.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "config = fluid.core.AnalysisConfig(model_dir + '/__model__',\n                                   model_dir + '/params')\nconfig.disable_gpu()\nconfig.switch_ir_optim(False)\npaddle_predictor = fluid.core.create_paddle_predictor(config)\ndata = fluid.core.PaddleTensor(x_data)\npaddle_out = paddle_predictor.run([data])\nres_paddle = paddle_out[0].as_ndarray()\nprint(\"Paddle Execution Done!\\n =============================\")\nprint(\"Verification result is: \", np.allclose(res_cinn, res_paddle, atol=1e-3))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}