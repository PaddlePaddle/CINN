{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Schedule Primitives in CINN\n\nIn this tutorial, we will guide you through the examples of using schedule primitives.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import cinn\nimport numpy as np\n# sphinx_gallery_thumbnail_path = './paddlepaddle.png'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "declare some variables for latter use\nExpr is short for expression.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "m = cinn.Expr(32)\nn = cinn.Expr(8)\n\nprint(m, n)\n# get the integer contained in an integer expression\nprint(m.int())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A schedule can be created from a list of Tensors.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# declare an elementwise multiply\nA = cinn.Placeholder('float32', 'A', (m, n))\nB = cinn.Placeholder('float32', 'B', (m, n))\nC = cinn.compute((m, n), lambda v: A(v[0], v[1]) * B(v[0], v[1]), name='C')\n\n# create the stages for further schedule\nstages = cinn.create_stages([C])\n\n# lower will transform the computation to real code\nfn = cinn.lower(\"fn\", stages, [A.to_tensor(), B.to_tensor(), C])\nprint(fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "One schedule is composed by multiple stages. We provide several\nmethods to schedule each stage.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## split\n:code:`split` can partition a specific axis into two axises by :code: `factor`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "A = cinn.Placeholder('float32', 'A', (m, ))\nB = cinn.compute((m, ), lambda v: A(v[0]) * 2., name='B')\n\nstages = cinn.create_stages([B])\ni0, i1 = stages[B].split(level=0, factor=4)\nfn = cinn.lower(\"fn\", stages, [A.to_tensor(), B])\nprint(fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## fuse\n:code:`fuse` can fuse two specific axises into a axis.\nIt is the reverse operation of `split`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "A = cinn.Placeholder('float32', 'A', (m, n))\nB = cinn.compute((m, n), lambda v: A(v[0], v[1]) * 2., name='B')\n\nstages = cinn.create_stages([B])\ni0 = stages[B].fuse(level0=0, level1=1)\nfn = cinn.lower(\"fn\", stages, [A.to_tensor(), B])\nprint(fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## tile\n:code:`tile` can partition two adjacent axises into blocks.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "A = cinn.Placeholder('float32', 'A', (m, n))\nB = cinn.Placeholder('float32', 'B', (m, n))\nC = cinn.compute((m, n), lambda v: A(v[0], v[1]) * B(v[0], v[1]), name='C')\n\nstages = cinn.create_stages([C])\n\ni, j = stages[C].axis(0), stages[C].axis(1)\ni_outer, i_inner, j_inner, j_outer = stages[C].tile(i, j, 4, 4)\nfn = cinn.lower(\"fn\", stages, [A.to_tensor(), B.to_tensor(), C])\nprint(fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## reorder\n:code:`reorder` can reorder the axises in the specified order.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "A = cinn.Placeholder('float32', 'A', (m, n))\nB = cinn.Placeholder('float32', 'B', (m, n))\nC = cinn.compute((m, n), lambda v: A(v[0], v[1]) * B(v[0], v[1]), name='C')\n\nstages = cinn.create_stages([C])\ni0, i1 = stages[C].axis(0), stages[C].axis(1)\nstages[C].reorder([i1, i0])\n\nfn = cinn.lower(\"fn\", stages, [A.to_tensor(), B.to_tensor(), C])\nprint(fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## unroll\n:code:`unroll` unroll a specific axis.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "A = cinn.Placeholder('float32', 'A', (m, n))\nB = cinn.Placeholder('float32', 'B', (m, n))\nC = cinn.compute((m, n), lambda v: A(v[0], v[1]) * B(v[0], v[1]), name='C')\n\nstages = cinn.create_stages([C])\ni1 = stages[C].axis(1)\nstages[C].unroll(i1)\n\nfn = cinn.lower(\"fn\", stages, [A.to_tensor(), B.to_tensor(), C])\nprint(fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## compute_inline\n:code:`compute_inline` marks a stage as inline, then the computation\nbody will be expanded and inserted at the location where the tensor\nis referenced.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "A = cinn.Placeholder('float32', 'A', (m, n))\nB = cinn.Placeholder('float32', 'B', (m, n))\nC = cinn.compute((m, n), lambda v: A(v[0], v[1]) * B(v[0], v[1]), name='C')\n\n# C1[i,j] = C[i,j] + B[i,j]\nC1 = cinn.compute([m, n], lambda v: C(v[0], v[1]) + B(v[0], v[1]), \"C1\")\n# C2[i,j] = C1[i,j] + B[i,j]\nC2 = cinn.compute([m, n], lambda v: C1(v[0], v[1]) + B(v[0], v[1]), \"C2\")\n\nstages = cinn.create_stages([C, C1, C2])\n\nstages[C].compute_inline()\nstages[C1].compute_inline()\n\nfn = cinn.lower(\"fn\", stages, [A.to_tensor(), B.to_tensor(), C2])\nprint(fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## bind\n:code:`bind` can bind a specified axis with a thread axis.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "A = cinn.Placeholder('float32', 'A', (m, n))\nB = cinn.Placeholder('float32', 'B', (m, n))\nC = cinn.compute((m, n), lambda v: A(v[0], v[1]) * B(v[0], v[1]), name='C')\n\nstages = cinn.create_stages([C])\nstages[C].bind(0, \"blockIdx.x\")\nstages[C].bind(1, \"threadIdx.x\")\n\nfn = cinn.lower(\"fn\", stages, [A.to_tensor(), B.to_tensor(), C])\nprint(fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## compute_at\n:code:`compute_at` can specify the stage to be computed at\nanother stage's scope.\nThe input param `other` specifies the other stage.\nThe input param `level` specifies the stage's scope(which loop)\nto be computed at.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "A = cinn.Placeholder('float32', 'A', (m, n, n))\nB = cinn.Placeholder('float32', 'B', (m, n, n))\nC = cinn.compute(\n    (m, n), lambda v: A(v[0], v[1], v[1]) * B(v[0], v[1], v[1]), name='C')\nD = cinn.compute((m, n), lambda v: C(v[0], v[1]) + 1., name='D')\nstages = cinn.create_stages([C, D])\n\nprint(\"---------Before compute_at---------\")\nfn = cinn.lower(\"fn\", stages, [A.to_tensor(), B.to_tensor(), C, D])\nprint(fn)\n\nprint(\"---------After compute_at---------\")\nstages[C].compute_at(other=stages[D], level=1)\nfn2 = cinn.lower(\"fn\", stages, [A.to_tensor(), B.to_tensor(), C, D])\nprint(fn2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## cache_read\n:code:`cache_read` can create a cache Tensor and load the origin\nTensor's data into this buffer.\nIt will replace all the reading in the readers with the cache.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "A = cinn.Placeholder('float32', 'A', (m, n))\nB = cinn.compute((m, n), lambda v: A(v[0], v[1]) * 2., name='B')\n\nstages = cinn.create_stages([B])\nACR = stages[A.to_tensor()].cache_read(\"local\", [B], stages)\nfn = cinn.lower(\"fn\", stages, [A.to_tensor(), ACR, B])\nprint(fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## cache_write\n:code:`cache_write` can create a cache for writing to the\noriginal tensor.\nIt will store the data in the cache memory first, then\nwrite to the output tensor.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "A = cinn.Placeholder('float32', 'A', (m, n))\nB = cinn.compute((m, n), lambda v: A(v[0], v[1]) * 2., name='B')\n\nstages = cinn.create_stages([B])\nBCR = stages[B].cache_write(\"local\", stages, B)\nfn = cinn.lower(\"fn\", stages, [A.to_tensor(), B, BCR])\nprint(fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parallel\n:code:`parallel` will mark one loop to execute in parallel.(Only used in X86 backends)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "A = cinn.Placeholder('float32', 'A', (m, n))\nB = cinn.compute((m, n), lambda v: A(v[0], v[1]) * 2., name='B')\n\nstages = cinn.create_stages([B])\nstages[B].parallel(0)\nfn = cinn.lower(\"fn\", stages, [A.to_tensor(), B])\nprint(fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Vectorize\n:code:`vectorize` will vectorize one loop in param `level`.(Only used in X86 backends)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "A = cinn.Placeholder('float32', 'A', (m, n))\nB = cinn.compute((m, n), lambda v: A(v[0], v[1]) * 2., name='B')\n\nstages = cinn.create_stages([B])\nstages[B].vectorize(0, 10)\nfn = cinn.lower(\"fn\", stages, [A.to_tensor(), B])\nprint(fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### An example of optimizing performance in cuda backends\n\n**In this section, we will show you a practical example about optimizing performance using schedule primitives**\n\nOptimize an elementwise_add kernel using `fuse`, `split` and `bind`\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "A = cinn.Placeholder('float32', 'A', (m, m))\nB = cinn.compute((m, m), lambda v: A([v[0], v[1]]) * 2., name='B')\n\nstages = cinn.create_stages([B])\nfn0 = cinn.lower(\"fn\", stages, [A.to_tensor(), B])\nprint(\"Original kernel before optimizing:\\n\", fn0)\nstages[B].fuse(0, 1)\nstages[B].split(level=0, factor=256)\nstages[B].bind(0, \"blockIdx.x\")\nstages[B].bind(1, \"threadIdx.x\")\nfn1 = cinn.lower(\"fn\", stages, [A.to_tensor(), B])\nprint(\"\\n======================================\\nThe optimized kernel:\\n\", fn1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Thus we get an optimized kernel.\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}