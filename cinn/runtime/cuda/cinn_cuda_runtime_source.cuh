/**
 * \file This file contains all the intrinsics available to be used in CUDA code generated by CodeGen.
 */

#define FN(x) cinn_nvgpu_ ## x ## _fp32
// NOTE Due to function override, we don't need to use type (such as '_fp32') as the suffix of function's name.
__device__ inline float FN(sin)(float x) { return sin(x); }
__device__ inline float FN(cos)(float x) { return cos(x); }
__device__ inline float FN(cosh)(float x) { return cosh(x); }
__device__ inline float FN(tanh)(float x) { return tanh(x); }

__device__ inline float FN(asin)(float x) { return asin(x); }
__device__ inline float FN(acos)(float x) { return acos(x); }
__device__ inline float FN(acosh)(float x) { return acosh(x); }
__device__ inline float FN(atanh)(float x) { return atanh(x); }

__device__ inline float FN(ceil)(float x) { return ceil(x); }
__device__ inline float FN(round)(float x) { return round(x); }
__device__ inline float FN(trunc)(float x) { return trunc(x); }
__device__ inline float FN(abs)(float x) { return abs(x); }
__device__ inline float FN(floor)(float x) { return floor(x); }
__device__ inline float FN(log)(float x) { return log(x); }
__device__ inline float FN(log2)(float x) { return log2(x); }
__device__ inline float FN(log10)(float x) { return log10(x); }
__device__ inline float FN(exp)(float x) { return exp(x); }
__device__ inline float FN(erf)(float x) { return erf(x); }
__device__ inline float FN(sigmoid)(float x) { return 1. / (1 + exp(-x)); }
__device__ inline float FN(sqrt)(float x) { return sqrt(x); }
__device__ inline float FN(rsqrt)(float x) { return rsqrt(x); }

__device__ inline bool FN(isfinite)(float x) { return isfinite(x); }
__device__ inline bool FN(isinf)(float x) { return isinf(x); }
__device__ inline bool FN(isnan)(float x) { return isnan(x); }

__device__ inline float FN(max)(float a, float b) { return max(a, b); }
__device__ inline float FN(min)(float a, float b) { return min(a, b); }

#undef FN

__device__ inline float cinn_warp_reduce_max(const float *buf, int offset, int extend) {
  float maxv = -3.402823e+38f;
  for (int i = threadIdx.x; i < extend; i += 32) {
    maxv = max(maxv, buf[offset + i]);
  }
  unsigned int mask;
  mask = __activemask();
  maxv = max(maxv, __shfl_down_sync(mask, maxv, 16, 32));
  maxv = max(maxv, __shfl_down_sync(mask, maxv, 8, 32));
  maxv = max(maxv, __shfl_down_sync(mask, maxv, 4, 32));
  maxv = max(maxv, __shfl_down_sync(mask, maxv, 2, 32));
  maxv = max(maxv, __shfl_down_sync(mask, maxv, 1, 32));
  maxv = __shfl_sync(mask, maxv, 0, 32);
  return maxv;
}

__device__ inline float cinn_warp_reduce_avg(const float *buf, int offset, int extend) {
  float sumv = 0;
  for (int i = threadIdx.x; i < extend; i += 32) {
    sumv += buf[offset + i] / (float)extend;
  }
  unsigned int mask;
  mask = __activemask();
  sumv += __shfl_down_sync(mask, sumv, 16, 32);
  sumv += __shfl_down_sync(mask, sumv, 8, 32);
  sumv += __shfl_down_sync(mask, sumv, 4, 32);
  sumv += __shfl_down_sync(mask, sumv, 2, 32);
  sumv += __shfl_down_sync(mask, sumv, 1, 32);
  sumv = __shfl_sync(mask, sumv , 0, 32);
  return sumv;
}

__device__ inline float cinn_warp_reduce_sum(const float *buf, int offset, int extend) {
  float sumv = 0;
  for (int i = threadIdx.x; i < extend; i += 32) {
    sumv += buf[offset + i];
  }
  unsigned int mask;
  mask = __activemask();
  sumv += __shfl_down_sync(mask, sumv, 16, 32);
  sumv += __shfl_down_sync(mask, sumv, 8, 32);
  sumv += __shfl_down_sync(mask, sumv, 4, 32);
  sumv += __shfl_down_sync(mask, sumv, 2, 32);
  sumv += __shfl_down_sync(mask, sumv, 1, 32);
  sumv = __shfl_sync(mask, sumv , 0, 32);
  return sumv;
}



